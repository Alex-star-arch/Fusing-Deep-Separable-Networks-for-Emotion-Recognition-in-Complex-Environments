# Fusing Deep Separable Networks for Emotion Recognition in Complex Environments
The detailed data processing will not be visible for a while until the paper is published to ensure data privacy and security, but don't worry, it will be released soon after the paper is published.
## Abstract
This research is dedicated to addressing the challenges of model training and application implementation in the field of traditional face emotion recognition. The proposed scheme is a lightweight facial emotion recognition system based on deep separable networks. The scheme optimizes the Xception network structure in three stages. Initially, the residual module and the deep separable module are combined in order to enhance the efficiency of feature extraction. Subsequently, global average pooling is employed in lieu of the traditional fully connected layer, thereby reducing the number of parameters. Finally, the channel information is integrated through the 2Ã—2 convolution and the point-by-point convolution, which effectively minimizes the loss of information while retaining more valuable feature information. The solution employs the Fer2013 dataset from the Kaggle platform for training with the objective of enhancing the accuracy of emotion recognition in diverse and complex environments within a simulated real-world setting. Furthermore, the objective is to develop a lightweight model that can be deployed in practical applications. The recognition accuracy has now reached an industry-leading level. Moreover, the project has developed a face emotion recognition system that has been validated through the construction of a real-time vision system. This system is capable of completing the tasks of face detection and emotion classification in complex environments, thus providing a solid foundation for the practical application of emotion recognition technology.
## Notebook
The requisite libraries and plugins for running the environment can be found here. Our code is written in Python 3.7. The code for our backbone network structure can be found in the "model" folder.
Once the environment has been configured correctly, the network model should be trained with "train_emotion_classifier.py". The trained model will then be automatically saved to the user's device. This model can then be used to perform the corresponding emotion recognition task.
Further details regarding the experiment and related explanations can be found in the code comments.
